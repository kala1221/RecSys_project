{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld3976Lwh2rx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#questo\n",
        "%%cython\n",
        "import numpy as np\n",
        "cimport numpy as np\n",
        "from libc.stdint cimport int32_t\n",
        "import time\n",
        "\n",
        "cdef inline double sign(double x):\n",
        "    if x > 0:\n",
        "        return 1.0\n",
        "    elif x < 0:\n",
        "        return -1.0\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "def do_some_training_EN(\n",
        "    URM_train,\n",
        "    double initial_learning_rate,\n",
        "    double regularization_2,\n",
        "    double l1_ratio,\n",
        "    double decay_rate,\n",
        "    int num_iterations,\n",
        "    double[:, :] existing_item_item_S,\n",
        "    double[:, :] S_icm,     # New parameter\n",
        "    double alpha           # New parameter\n",
        "):\n",
        "    cdef int n_items = URM_train.shape[1]\n",
        "    URM_train_csr = URM_train.tocsr()\n",
        "    URM_train_coo = URM_train.tocoo()\n",
        "    cdef long start_time = time.time()\n",
        "    cdef int32_t[:] indices = URM_train_csr.indices.view(dtype=np.int32)\n",
        "    cdef int32_t[:] indptr = URM_train_csr.indptr.view(dtype=np.int32)\n",
        "    cdef double[:] data = URM_train_csr.data.view(dtype=np.float64)\n",
        "    cdef int32_t[:] coo_row = URM_train_coo.row.view(dtype=np.int32)\n",
        "    cdef int32_t[:] coo_col = URM_train_coo.col.view(dtype=np.int32)\n",
        "    cdef double[:] coo_data = URM_train_coo.data.view(dtype=np.float64)\n",
        "\n",
        "    cdef double[:, :] item_item_S\n",
        "    if existing_item_item_S is not None:\n",
        "        item_item_S = existing_item_item_S\n",
        "    else:\n",
        "        item_item_S = np.zeros((n_items, n_items), dtype=np.float64)\n",
        "\n",
        "    cdef double learning_rate = initial_learning_rate\n",
        "    cdef double loss = 0.0\n",
        "    cdef double prediction_error, predicted_rating, profile_rating\n",
        "    cdef int user_id, item_id, profile_item_id, sample_index, index\n",
        "    cdef int start_idx, end_idx\n",
        "    cdef int32_t[:] random_indices = np.random.randint(0, URM_train_coo.nnz, size=num_iterations).astype(np.int32)\n",
        "     # Early stopping variables\n",
        "    cdef int patience_counter = 0\n",
        "    cdef double last_loss = np.inf\n",
        "    cdef int patience = 20\n",
        "    cdef double min_delta = 1e-5\n",
        "    cdef int warm_restart = 0\n",
        "    for sample_num in range(num_iterations+1):\n",
        "        sample_index = random_indices[sample_num]\n",
        "        user_id = coo_row[sample_index]\n",
        "        item_id = coo_col[sample_index]\n",
        "        true_rating = coo_data[sample_index]\n",
        "\n",
        "        predicted_rating = 0.0\n",
        "        start_idx = indptr[user_id]\n",
        "        end_idx = indptr[user_id + 1]\n",
        "\n",
        "        for index in range(start_idx, end_idx):\n",
        "            profile_item_id = indices[index]\n",
        "            profile_rating = data[index]\n",
        "            predicted_rating += profile_rating * item_item_S[profile_item_id, item_id]\n",
        "\n",
        "        prediction_error = true_rating - predicted_rating\n",
        "        loss += prediction_error ** 2\n",
        "\n",
        "        for index in range(start_idx, end_idx):\n",
        "            profile_item_id = indices[index]\n",
        "            profile_rating = data[index]\n",
        "            item_item_S[profile_item_id, item_id] += learning_rate * (\n",
        "                prediction_error * profile_rating\n",
        "                - (1 - l1_ratio) * regularization_2 * item_item_S[profile_item_id, item_id]\n",
        "                - l1_ratio * sign(item_item_S[profile_item_id, item_id])\n",
        "                - alpha * (item_item_S[profile_item_id, item_id] - S_icm[profile_item_id, item_id]) #new for icm\n",
        "            )\n",
        "        if sample_num % 5000 == 0:\n",
        "            learning_rate *= decay_rate\n",
        "            if sample_num > 0:\n",
        "              current_loss = loss / sample_num\n",
        "            else:\n",
        "              current_loss=0\n",
        "            #loss_history.append(current_loss)\n",
        "            if sample_num % 1000000 == 0:\n",
        "                  elapsed_time = time.time() - start_time\n",
        "                  samples_per_second = sample_num / elapsed_time\n",
        "                  print(\n",
        "                      \"Iteration {} in {:.2f} seconds, loss is {:.4f}. Samples per second {:.2f}\".format(\n",
        "                          sample_num, elapsed_time, current_loss, samples_per_second\n",
        "                      )\n",
        "                  )\n",
        "            # Early stopping check\n",
        "            if abs(last_loss - current_loss) < min_delta or current_loss > 1:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    if warm_restart == 0:\n",
        "                        learning_rate = initial_learning_rate\n",
        "                        warm_restart += 1\n",
        "                        patience_counter = 0\n",
        "                        print(\"warm restart\")\n",
        "                    else:\n",
        "                        print(\"Early stopping at iteration {}. Loss has not improved significantly for {} iterations, or has stayed above 1 too much. loss was {}\".format(sample_num, patience * 5000, current_loss))\n",
        "                        break\n",
        "            else:\n",
        "                patience_counter = 0  # Reset patience counter if loss improves\n",
        "            last_loss = current_loss\n",
        "\n",
        "    return loss, item_item_S\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sljJSJjJ3mXx",
        "outputId": "c1b81e4e-53f1-4233-d6ea-369daf2926b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "performance hint: /root/.cache/ipython/cython/_cython_magic_793d7496f50a3060672d684fead44deb3ce1ba1a.pyx:56:38: Index should be typed for more efficient access\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of stderr:\n",
            "In file included from /usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929,\n",
            "                 from /usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12,\n",
            "                 from /usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/arrayobject.h:5,\n",
            "                 from /root/.cache/ipython/cython/_cython_magic_793d7496f50a3060672d684fead44deb3ce1ba1a.c:1250:\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2: warning: #warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [-Wcpp]\n",
            "   17 | #warning \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  ^~~~~~~"
          ]
        }
      ]
    }
  ]
}